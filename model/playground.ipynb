{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "old_basepath = '../basedata/PCD Data/Data before 2020-9'\n",
    "new_basepath = '../basedata/PCD Data/Data after 2020-7/PCD data after 2020-7.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import os \n",
    "import os.path as osp \n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import math \n",
    "from tqdm.notebook import tqdm \n",
    "import random\n",
    "\n",
    "import torch \n",
    "from torch import nn \n",
    "import torch.nn.functional as F \n",
    "from torch import optim \n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_lat_long = pd.read_csv('prepared_data/others/station_lat_long.csv', usecols=['stationIDs', 'lats', 'longs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_lat_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listdir(data_base_path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_lat_long.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 101.0.4951\n",
      "Get LATEST chromedriver version for 101.0.4951 google-chrome\n",
      "Driver [/Users/grniss/.wdm/drivers/chromedriver/mac64_m1/101.0.4951.41/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "service = ChromeService(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "import time\n",
    "\n",
    "def scrape(url):\n",
    "    # url = f'https://earth.nullschool.net/chem/surface/level/anim=off/overlay=so2smass/equirectangular/loc={lng},{lat}'\n",
    "    #go to web/#current\n",
    "    driver.get(url=url)\n",
    "    element = WebDriverWait(driver,9999).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"spotlight-panel\"]/div[3]/div')))\n",
    "    data_status = driver.find_element(By.XPATH,'/html/body/main/div[3]/div[1]/div')\n",
    "    if data_status.text==\"Downloading...\":\n",
    "        while True:\n",
    "            time.sleep(0.05)\n",
    "            data_status = driver.find_element(By.XPATH,'/html/body/main/div[3]/div[1]/div')\n",
    "            if data_status.text==\"Downloading...\":\n",
    "                continue\n",
    "            else :\n",
    "                break\n",
    "    #so2\n",
    "    data = element.text.split(' ')[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime 2021-07-18 00:00:00+07:00\n",
      "col Temp\n",
      "data 21.3\n",
      "datetime 2021-07-18 03:00:00+07:00\n",
      "col Temp\n",
      "data 21.3\n",
      "datetime 2021-07-18 06:00:00+07:00\n",
      "col Temp\n",
      "data 21.2\n",
      "datetime 2021-07-18 09:00:00+07:00\n",
      "col Temp\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/grniss/Documents/study/data science/final_project/model/playground.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grniss/Documents/study/data%20science/final_project/model/playground.ipynb#ch0000037?line=39'>40</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m'\u001b[39m, datetime)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grniss/Documents/study/data%20science/final_project/model/playground.ipynb#ch0000037?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mcol\u001b[39m\u001b[39m'\u001b[39m, col)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/grniss/Documents/study/data%20science/final_project/model/playground.ipynb#ch0000037?line=41'>42</a>\u001b[0m data \u001b[39m=\u001b[39m scrape(urls[col])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grniss/Documents/study/data%20science/final_project/model/playground.ipynb#ch0000037?line=42'>43</a>\u001b[0m df\u001b[39m.\u001b[39mloc[datetime, col] \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grniss/Documents/study/data%20science/final_project/model/playground.ipynb#ch0000037?line=43'>44</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, data)\n",
      "\u001b[1;32m/Users/grniss/Documents/study/data science/final_project/model/playground.ipynb Cell 8'\u001b[0m in \u001b[0;36mscrape\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grniss/Documents/study/data%20science/final_project/model/playground.ipynb#ch0000044?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m data_status\u001b[39m.\u001b[39mtext\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading...\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grniss/Documents/study/data%20science/final_project/model/playground.ipynb#ch0000044?line=17'>18</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/grniss/Documents/study/data%20science/final_project/model/playground.ipynb#ch0000044?line=18'>19</a>\u001b[0m         time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.05\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grniss/Documents/study/data%20science/final_project/model/playground.ipynb#ch0000044?line=19'>20</a>\u001b[0m         data_status \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mXPATH,\u001b[39m'\u001b[39m\u001b[39m/html/body/main/div[3]/div[1]/div\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/grniss/Documents/study/data%20science/final_project/model/playground.ipynb#ch0000044?line=20'>21</a>\u001b[0m         \u001b[39mif\u001b[39;00m data_status\u001b[39m.\u001b[39mtext\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading...\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "station_lat_long = pd.read_csv('prepared_data/others/station_lat_long.csv', usecols=['stationIDs', 'lats', 'longs'])\n",
    "data_base_path = 'prepared_data/stations'\n",
    "to_use_base_path = 'prepared_data/to_uses'\n",
    "scraped_base_path = 'prepared_data/scraped'\n",
    "start = 0\n",
    "stop = 1\n",
    "for i in range(start, stop):\n",
    "    cur_station = station_lat_long.iloc[i]\n",
    "    fn = f'{cur_station.stationIDs}.csv'\n",
    "    df = pd.read_csv(join(data_base_path, fn)).set_index('datetime')\n",
    "    to_use = pd.read_csv(join(to_use_base_path, fn)).set_index('datetime')\n",
    "    df = df.loc[to_use.index]\n",
    "    df['set_no'] = to_use['set_no']\n",
    "    df.index = pd.to_datetime(df.index , format='%Y-%m-%d %H:%M:%S%z')\n",
    "    for datetime in df.index:\n",
    "        datetime_utc = datetime.astimezone(pytz.utc)\n",
    "        lat = station_lat_long.iloc[i]['lats']\n",
    "        lng = station_lat_long.iloc[i]['longs']\n",
    "        year = datetime_utc.year\n",
    "        month = datetime_utc.month\n",
    "        day = datetime_utc.day\n",
    "        hour = datetime_utc.hour\n",
    "        urls = {\n",
    "            'PM25':f'https://earth.nullschool.net/#{year}/{month}/{day}/{hour}00Z/particulates/surface/level/anim=off/overlay=pm2.5/equirectangular/loc={lng},{lat}',\n",
    "            'PM10':f'https://earth.nullschool.net/#{year}/{month}/{day}/{hour}00Z/particulates/surface/level/anim=off/overlay=pm10/equirectangular/loc={lng},{lat}',\n",
    "            'NO2':f'https://earth.nullschool.net/#{year}/{month}/{day}/{hour}00Z/chem/surface/level/anim=off/overlay=no2/equirectangular/loc={lng},{lat}',\n",
    "            'SO2':f'https://earth.nullschool.net/#{year}/{month}/{day}/{hour}00Z/chem/surface/level/anim=off/overlay=so2smass/equirectangular/loc={lng},{lat}',\n",
    "            'CO':f'https://earth.nullschool.net/#{year}/{month}/{day}/{hour}00Z/chem/surface/level/anim=off/overlay=cosc/equirectangular/loc={lng},{lat}',\n",
    "            'Rain':f'https://earth.nullschool.net/#{year}/{month}/{day}/{hour}00Z/wind/surface/level/anim=off/overlay=relative_humidity/equirectangular/loc={lng},{lat}',\n",
    "            'Temp':f'https://earth.nullschool.net/#{year}/{month}/{day}/{hour}00Z/wind/surface/level/anim=off/overlay=temp/equirectangular/loc={lng},{lat}'\n",
    "        }\n",
    "        cur_row = df.loc[datetime]\n",
    "        na_checker = cur_row.isna()\n",
    "        for col in cur_row.index:\n",
    "            if na_checker[col] and col in urls:\n",
    "                data = scrape(urls[col])\n",
    "                df.loc[datetime, col] = data\n",
    "    df.to_csv(join(scraped_base_path, fn))\n",
    "                \n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp\n",
      "Rain\n",
      "SO2\n"
     ]
    }
   ],
   "source": [
    "for col in cur_row.index:\n",
    "            if na_checker[col] and col in urls:\n",
    "                print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "865272"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "\n",
    "data_base_path = 'prepared_data/stations'\n",
    "to_use_base_path = 'prepared_data/to_uses'\n",
    "count = 0\n",
    "start = 0\n",
    "i = 0\n",
    "for station in listdir(data_base_path):\n",
    "    if start <= i:\n",
    "        df = pd.read_csv(join(data_base_path, station))\n",
    "        to_use = pd.read_csv(join(to_use_base_path, station))\n",
    "        df = df.set_index('datetime').loc[to_use['datetime']]\n",
    "        count += df[['CO', 'NO2', 'SO2', 'O3', 'PM10', 'Temp', 'Rain', 'PM25']].isna().sum().sum()\n",
    "        # for col in df.columns:\n",
    "        #     for dt in df[col][df[col].isna()]:\n",
    "        #         scrape(lat, long, datetime, col)\n",
    "    i += 1\n",
    "    # if((df.isna().sum() > 0).sum() > 1):\n",
    "    #     print((df.isna().sum() > 0).sum() > 1)\n",
    "    #     break\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "pd.to_datetime(df.index, format='%Y-%m-%d %H:%M:%S%z')[0].astimezone(pytz.utc).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df.index, format='%Y-%m-%d %H:%M:%S%z')[0].astimezone(pytz.utc).hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "service = ChromeService(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
